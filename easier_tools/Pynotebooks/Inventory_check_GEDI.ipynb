{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5eea04-0e4d-4bc4-a5b1-67ee0ca4cae6",
   "metadata": {},
   "source": [
    "# Collection of geospatial data and STAC - GEDI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429f2e2-9180-45eb-b664-8544c6eccd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc0dc3-bff5-4bcb-beb6-d579318e6363",
   "metadata": {},
   "source": [
    "## Manage inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2573a90-4919-45aa-8508-21c65c12518b",
   "metadata": {},
   "source": [
    "### Initialize inventory\n",
    "There are four levels of GEDI data, with the Web Interface from two sites:\n",
    "\n",
    "Level 1 and Level 2 : https://e4ftl01.cr.usgs.gov/GEDI/\n",
    "\n",
    "Level 3 and Level 4 : https://daac.ornl.gov/daacdata/gedi/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b1f72d-7afa-48cd-a3af-92a6c1b1e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base url for L1/L2 products\n",
    "avail_products = [\"GEDI01_B.002\", \"GEDI02_A.002\", \"GEDI02_B.002\"]\n",
    "product = avail_products[2]\n",
    "url = f\"https://e4ftl01.cr.usgs.gov/GEDI/{product}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29490436-390c-4e94-922e-700349f1802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate base url for L3/L4 products\n",
    "l3l4_products = [\n",
    "    \"GEDI_L3_LandSurface_Metrics_V2\",\n",
    "    \"GEDI_L4A_AGB_Density_V2_1\",\n",
    "    \"GEDI_L4A_AGB_Density_GW\",\n",
    "    \"GEDI_L4B_Gridded_Biomass\",\n",
    "]\n",
    "product = l3l4_products[2]\n",
    "url = f\"https://daac.ornl.gov/daacdata/gedi/{product}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df9123-0377-41aa-9ba0-df8896f1c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection the sublevel directory URL into next_level_links\n",
    "response = requests.get(url)\n",
    "next_level_links = []\n",
    "valid = False\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = soup.find_all(\"a\", href=True)  # find all <a> elements with href attribute\n",
    "    for link in links:\n",
    "        if valid:\n",
    "            next_level_links.append(url + link[\"href\"])\n",
    "        if link.get_text() == \"Parent Directory\":\n",
    "            valid = True\n",
    "else:\n",
    "    print(\"Failed to retrieve directory listing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f8f22-8c3e-4e20-80d1-9c9987e7ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_level_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf55d70-58f3-4898-8962-750e30fd7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recurisively collection download links for individual files into direct_download_links\n",
    "direct_download_links = []\n",
    "\n",
    "\n",
    "def get_file_dict(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        valid = False\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        file_dict = {}\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        for link in links:\n",
    "            href = link[\"href\"]\n",
    "            if link.get_text() == \"Parent Directory\":\n",
    "                valid = True\n",
    "            elif valid:\n",
    "                if href.endswith(\"/\"):\n",
    "                    subdir_url = url + href\n",
    "                    subdir_dict = get_file_dict(\n",
    "                        subdir_url\n",
    "                    )  # recursively call get_file_dict for subdirectory\n",
    "                    file_dict.update(subdir_dict)\n",
    "                else:\n",
    "                    direct_download_links.append(url + href)\n",
    "                    file_dict[link.text] = url + href\n",
    "        return file_dict\n",
    "    else:\n",
    "        print(f\"Failed to retrieve directory listing for {url}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adc249-1d16-485a-a8b6-accfbc7c622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all direct_download_links\n",
    "for l in tqdm.tqdm(next_level_links):\n",
    "    day_file_dict = get_file_dict(l)\n",
    "    # print(len(day_file_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefeb064-cc86-4d1a-82e8-47ce4000d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the download links as initial inventory database (as a csv table)\n",
    "# this table will be used to track the status of download when there is an interrupt.\n",
    "today_s = datetime.datetime.now().date().strftime(\"%m-%d-%Y\")\n",
    "init_inventory = pd.DataFrame(\n",
    "    {\"file_location\": direct_download_links, \"cache\": \"no\", \"last_check\": \"\"}\n",
    ")\n",
    "init_inventory.to_csv(f\"../../data/gedi/inventory_{product}_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e37e76-6735-442a-b9a6-7acd906727d5",
   "metadata": {},
   "source": [
    "### Data collection in background\n",
    "\n",
    "Two separate scripts to run for L1L2 and L3L4 since the authentication process are different.\n",
    "\n",
    "- Usage\n",
    "\n",
    "To download product of Level 1B, 2A, and 2B, run `pyScripts/daac_pool.py -p [1B|2A|2B]`\n",
    "\n",
    "To download product of Level 3 and 4, run `pyScripts/daac_session.py -p [3|4A|4A_GW|4B]`\n",
    "\n",
    "- Note\n",
    "\n",
    "The script will utilize multi-processing. Change `num_threads = 16` for another number of cores to use.\n",
    "Authentication file needed at location `~/.netrc`, with format:\n",
    "The script will only download the file that is marked as `no` in the inventory table `/data/gedi/inventory_[collection_short_name]_latest.csv`\n",
    "\n",
    "<pre><code>\n",
    "machine urs.earthdata.nasa.gov\n",
    "login USERNAME\n",
    "password PASSWORD\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f73c8-3f02-400f-904a-7b2e6867af72",
   "metadata": {},
   "source": [
    "### Inventory check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f01f4c-e0db-43f8-8af6-6643e636493c",
   "metadata": {},
   "source": [
    "Available collection name\n",
    "\n",
    "\"GEDI01_B.002\",\n",
    "\"GEDI02_A.002\",\n",
    "\"GEDI02_B.002\",\n",
    "\"GEDI_L3_LandSurface_Metrics_V2\",\n",
    "\"GEDI_L4A_AGB_Density_V2_1\",\n",
    "\"GEDI_L4A_AGB_Density_GW_2028\",\n",
    "\"GEDI_L4B_Gridded_Biomass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019115e-ba2b-4c0d-b2af-7a0c9fe4f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"GEDI01_B.002\"\n",
    "inventory = pd.read_csv(f\"../../data/gedi/inventory_{product}_latest.csv\")\n",
    "local_cache_root = \"../../../daac_data_download_python/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9985101e-5bab-4a1a-ad83-8b7d328c3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT!! for level 1 and level 2\n",
    "def check_file(x, product):\n",
    "    fp = local_cache_root + product + x.split(product)[1]\n",
    "    # print(fp)\n",
    "    return \"yes\" if os.path.isfile(fp) else \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f77e16-2d39-4e05-9061-5b6bd2ca10d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT!! for level 3 and level 4\n",
    "def check_file(x, product):\n",
    "    fp = local_cache_root + product + x.split(\"gedi/\" + product)[1]\n",
    "    # print(fp)\n",
    "    return \"yes\" if os.path.isfile(fp) else \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774dde5-c080-415e-bfae-1044dfc3c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory[\"cache\"] = inventory.file_location.map(lambda x: check_file(x, product))\n",
    "today_s = datetime.datetime.now().date().strftime(\"%m-%d-%Y\")\n",
    "inventory.loc[inventory.cache == \"yes\", \"last_check\"] = today_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c2be6-97d1-4385-bd3b-0b1695b34c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show number of finished and todo\n",
    "inventory.cache.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf6d69-b5f3-46fd-8ab1-c53d1da79d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the database\n",
    "inventory.to_csv(f\"../../data/gedi/inventory_{product}_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1567d2-073a-4db5-8e67-dd69be031617",
   "metadata": {},
   "source": [
    "## STAC information\n",
    "Reference document: https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52182f97-3e38-415d-adf8-5b6211b60088",
   "metadata": {},
   "source": [
    "### List collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28e8b5-14b0-462c-90ee-8225999c179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gedi_product_query = \"https://cmr.earthdata.nasa.gov/search/collections?short_name=GEDI*&options[short_name][pattern]=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b008a-44cc-4b60-83c1-9448339c9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmr_response = requests.get(\n",
    "    f\"{gedi_product_query}\", headers={\"Accept\": \"application/json\"}\n",
    ").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e39514-0764-49d4-bf27-638b9aa196f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_metadata = pd.DataFrame(\n",
    "    [(x[\"id\"], x[\"short_name\"], x[\"title\"]) for x in cmr_response[\"feed\"][\"entry\"]],\n",
    "    columns=[\"id\", \"short_name\", \"title\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84adec93-87a4-4b2e-9a14-4deb24a76117",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a371b-37ac-48c3-834d-451c99f3804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt prompt input\n",
    "\"\"\"\n",
    "Write python code in jupyter cell: given a list of product `ids`, \n",
    "for each `id` in the list, make a directory under `data/gedi/` \n",
    "with the name of `id` and save the return json from \n",
    "the url `https://cmr.earthdata.nasa.gov/search/concepts/{id}.stac`\n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "# List of product ids\n",
    "ids = collection_metadata.id.tolist()\n",
    "\n",
    "base_directory = \"../../data/gedi/stac/\"\n",
    "\n",
    "# Create the base directory if it doesn't exist\n",
    "os.makedirs(base_directory, exist_ok=True)\n",
    "\n",
    "for id in ids:\n",
    "    directory_path = os.path.join(base_directory, str(id))\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "    url = f\"https://cmr.earthdata.nasa.gov/search/concepts/{id}.stac\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "        file_path = os.path.join(directory_path, f\"{id}.json\")\n",
    "\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(json_data, file, indent=4)\n",
    "\n",
    "        print(f\"JSON data saved for id: {id}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve JSON data for id: {id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00b68f-9631-41bd-9597-296713293ee3",
   "metadata": {},
   "source": [
    "### List items\n",
    "inspired by [GEDI finder code](https://git.earthdata.nasa.gov/projects/LPDUR/repos/gedi-finder-tutorial-python/browse/GEDI_Finder.py)\n",
    "to iteratively collect item json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a2746-8cc6-407d-a610-de583c1a0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_ids = dict(\n",
    "    zip(\n",
    "        collection_metadata.short_name,\n",
    "        collection_metadata.id,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a975d44-d543-4b51-aa9e-1db169052050",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4d9dd-f982-49ba-9800-26bd1b580c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"GEDI_L4B_Gridded_Biomass_2017\"\n",
    "concept_ids[product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00e632-23bb-46e7-8e18-e271e2c9ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base CMR granule search url, including LPDAAC provider name and max page size (2000 is the max allowed)\n",
    "cmr = \"https://cmr.earthdata.nasa.gov/search/granules.stac?pretty=true&page_size=2000&collection_concept_id=\"\n",
    "# CMR uses pagination for queries with more features returned than the page size\n",
    "page = 1\n",
    "\n",
    "try:\n",
    "\n",
    "    # Send GET request to CMR granule search endpoint w/ product concept ID, bbox & page number, format return as json\n",
    "    cmr_response = requests.get(f\"{cmr}{concept_ids[product]}&pageNum={page}\").json()[\n",
    "        \"features\"\n",
    "    ]\n",
    "\n",
    "    print(\"fetched page\", page)\n",
    "    # If 2000 features are returned, move to the next page and submit another request, and append to the response\n",
    "    while len(cmr_response) % 2000 == 0:\n",
    "        page += 1\n",
    "        cmr_response += requests.get(\n",
    "            f\"{cmr}{concept_ids[product]}&pageNum={page}\"\n",
    "        ).json()[\"features\"]\n",
    "        print(\"fetched page\", page)\n",
    "except:\n",
    "    # If the request did not complete successfully, print out the response from CMR\n",
    "    print(requests.get(f\"{cmr}{concept_ids[product]}&pageNum={page}\").json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ffd5f-12a1-4ef4-aa8a-0b07599d6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store each item into a separate json file\n",
    "item_dir = f\"../../data/gedi/stac/{concept_ids[product]}/items/\"\n",
    "os.makedirs(item_dir, exist_ok=True)\n",
    "\n",
    "for item in tqdm.tqdm(cmr_response):\n",
    "    item_id = item[\"id\"]\n",
    "    file_path = os.path.join(item_dir, f\"{item_id}.json\")\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(item, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
