{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import NoCredentialsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_scenes_list(many_scenes, batch_tag, batch_size=100):\n",
    "    batch_num = len(many_scenes) // batch_size + 1\n",
    "    if len(many_scenes) % batch_size == 0:\n",
    "        batch_num -= 1\n",
    "    import os\n",
    "\n",
    "    dest = f\"../../data/landsat/task/{batch_tag}\"\n",
    "    try:\n",
    "        os.makedirs(dest)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        pass\n",
    "    for i in range(1, batch_num + 1):\n",
    "        with open(f\"{dest}/scenes_{str(i).zfill(4)}.txt\", \"w\") as fp:\n",
    "            fp.write(\"landsat_ot_c2_l1|displayId\\n\")\n",
    "            for item in many_scenes[(i - 1) * batch_size : i * batch_size]:\n",
    "                # write each item on a new line\n",
    "                fp.write(f\"{item}\\n\")\n",
    "    print(\"Done\", batch_num)\n",
    "\n",
    "\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "\n",
    "def func_over_daterange(start_date, end_date, func):\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        print(single_date.strftime(\"%Y%m%d\"))\n",
    "        # call daily function\n",
    "        func(single_date.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = os.getenv(\"PIKNIK_ENDPOINT\")\n",
    "PROVIDER = os.getenv(\"PIKNIK_PROVIDER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = os.getenv(\"PIKNIK_ACCESS_KEY_ID\")\n",
    "SECRET_KEY = os.getenv(\"PIKNIK_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    "    endpoint_url=\"http://\" + ENDPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = s3.Bucket(\"uofm-data1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Upload missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/temp/missing_files_dump.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m----> 2\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(missing_files, fp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'missing_files' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/temp/missing_files_dump.json\", \"w\") as fp:\n",
    "    json.dump(missing_files, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/temp/missing_files_dump.json\", \"r\") as fp:\n",
    "    print(fp.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/temp/missing_files_dump.json\", \"r\") as fp:\n",
    "\n",
    "    if len(fp.readlines()) != 0:\n",
    "        print(fp.readlines())\n",
    "        fp.seek(0)\n",
    "        missing_files = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'missing_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m missing_files\n",
      "\u001b[0;31mNameError\u001b[0m: name 'missing_files' is not defined"
     ]
    }
   ],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LC09_L1GT_112068_20211103_20220118_02_T2',\n",
       "  ['LC09_L1GT_112068_20211103_20220118_02_T2_B6.TIF']),\n",
       " ('LC09_L1TP_192052_20211103_20220118_02_T1',\n",
       "  ['LC09_L1TP_192052_20211103_20220118_02_T1_thumb_small.jpeg',\n",
       "   'LC09_L1TP_192052_20211103_20220118_02_T1_stac.json',\n",
       "   'LC09_L1TP_192052_20211103_20220118_02_T1_thumb_large.jpeg']),\n",
       " ('LC09_L1TP_192053_20211103_20220118_02_T1',\n",
       "  ['LC09_L1TP_192053_20211103_20220118_02_T1_stac.json',\n",
       "   'LC09_L1TP_192053_20211103_20220118_02_T1_thumb_large.jpeg',\n",
       "   'LC09_L1TP_192053_20211103_20220118_02_T1_thumb_small.jpeg'])]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, missing_files[k]) for k in missing_files.keys() if get_dt_str(k) == \"20211103\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[s3.ObjectSummary(bucket_name='uofm-data1', key='landsat9-c2-l1/20211103/LC09_L1GT_112068_20211103_20220118_02_T2/LC09_L1GT_112068_20211103_20220118_02_T2_B5.TIF')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\n",
    "    my_bucket.objects.filter(\n",
    "        Prefix=\"landsat9-c2-l1/20211103/LC09_L1GT_112068_20211103_20220118_02_T2/LC09_L1GT_112068_20211103_20220118_02_T2_B5.TIF\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9432"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(my_bucket.objects.filter(Prefix=\"landsat9-c2-l1-missing\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LC09_L1TP_054023_20220101_20220123_02_T1',\n",
       "  ['LC09_L1TP_054023_20220101_20220123_02_T1_B4.TIF']),\n",
       " ('LC09_L1GT_111059_20220101_20220121_02_T2',\n",
       "  ['LC09_L1GT_111059_20220101_20220121_02_T2_thumb_small.jpeg']),\n",
       " ('LC09_L1GT_095122_20220101_20220122_02_T2',\n",
       "  ['LC09_L1GT_095122_20220101_20220122_02_T2_thumb_small.jpeg']),\n",
       " ('LC09_L1TP_111036_20220101_20220121_02_T1',\n",
       "  ['LC09_L1TP_111036_20220101_20220121_02_T1_QA_RADSAT.TIF',\n",
       "   'LC09_L1TP_111036_20220101_20220121_02_T1_SZA.TIF',\n",
       "   'LC09_L1TP_111036_20220101_20220121_02_T1_SAA.TIF'])]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s,fl in tqdm.tqdm(missing_files.items()):\n",
    "#     for f in fl:\n",
    "#         local_file = f'../../data/landsat/m2m_download/{get_dt_str(s)}/{s}/{f}'\n",
    "#         remote_key = f'landsat9-c2-l1/{get_dt_str(s)}/{s}/{f}'\n",
    "#         if os.path.exists(local_file):\n",
    "#             s3.meta.client.upload_file(local_file, 'uofm-data1', remote_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Checking integrity of S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files = {}\n",
    "scene_cnt = 0\n",
    "file_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asset_helper(href):\n",
    "    asset = href.split(\"/\")[-1]\n",
    "    if \".\" in asset:\n",
    "        return asset\n",
    "    else:\n",
    "        return asset + \"_stac.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_files = [obj.key.split('/')[-1] for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/20211103\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_s3_one_day(cur_date):\n",
    "    datestr = cur_date.strftime(\"%Y%m%d\")\n",
    "    remote_files = [\n",
    "        obj.key.split(\"/\")[-1]\n",
    "        for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/{datestr}\")\n",
    "    ]\n",
    "    stac_list = glob.glob(f\"../../data/stac/landsat-c2l1/json/{datestr}/*.json\")\n",
    "    scene_cnt = 0\n",
    "    file_cnt = 0\n",
    "    for sf in stac_list:\n",
    "        with open(sf, \"r\") as f:\n",
    "            import json\n",
    "\n",
    "            stac_objects = json.load(f)\n",
    "\n",
    "        diff = set(\n",
    "            [asset_helper(obj[\"href\"]) for k, obj in stac_objects[\"assets\"].items()]\n",
    "        ) - set(remote_files)\n",
    "        if diff:\n",
    "            missing_files[stac_objects[\"id\"]] = list(diff)\n",
    "            scene_cnt += 1\n",
    "            file_cnt += len(diff)\n",
    "\n",
    "    print(\"checked\", datestr, scene_cnt, file_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked 20211103 3 7\n"
     ]
    }
   ],
   "source": [
    "check_s3_one_day(date(2021, 11, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "# with Pool(20) as p:\n",
    "#     print(p.map(check_s3_one_day, daterange(start_date, end_date)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 366/366 [1:33:33<00:00, 15.34s/it]\n"
     ]
    }
   ],
   "source": [
    "start_date = date(2021, 10, 31)\n",
    "end_date = date(2022, 11, 1)\n",
    "\n",
    "for cur_date in tqdm.tqdm(\n",
    "    daterange(start_date, end_date), total=(end_date - start_date).days\n",
    "):\n",
    "    datestr = cur_date.strftime(\"%Y%m%d\")\n",
    "    remote_files = [\n",
    "        obj.key.split(\"/\")[-1]\n",
    "        for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/{datestr}\")\n",
    "    ]\n",
    "    stac_list = glob.glob(f\"../../data/stac/landsat-c2l1/json/{datestr}/*.json\")\n",
    "\n",
    "    for sf in stac_list:\n",
    "        with open(sf, \"r\") as f:\n",
    "            import json\n",
    "\n",
    "            stac_objects = json.load(f)\n",
    "\n",
    "        diff = set(\n",
    "            [asset_helper(obj[\"href\"]) for k, obj in stac_objects[\"assets\"].items()]\n",
    "        ) - set(remote_files)\n",
    "        if diff:\n",
    "            missing_files[stac_objects[\"id\"]] = list(diff)\n",
    "            scene_cnt += 1\n",
    "            file_cnt += len(diff)\n",
    "    # print(datestr,len(remote_files),scene_cnt,file_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding = [\n",
    "    \"LC09_L1TP_108078_20220520_20220520_02_T1_SAA.TIF\",\n",
    "    \"LC09_L1TP_108082_20220520_20220520_02_T1_VZA.TIF\",\n",
    "    \"LC09_L1TP_108083_20220520_20220520_02_T1_MTL.txt\",\n",
    "    \"LC09_L1GT_108057_20220520_20220520_02_T2_ANG.txt\",\n",
    "    \"LC09_L1TP_108233_20220520_20220520_02_T2_SZA.TIF\",\n",
    "    \"LC09_L1TP_108062_20220520_20220520_02_T1_VAA.TIF\",\n",
    "    \"LC09_L1TP_108070_20220520_20220520_02_T1_MTL.xml\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/output/missing_s3.txt\", \"r\") as fr:\n",
    "    missing_file_keys = fr.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_keys = [k.replace(\"\\n\", \"\") for k in missing_file_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in missing_file_keys:\n",
    "    shutil.copy(\n",
    "        \"../../data/landsat/\" + k,\n",
    "        \"../../data/landsat/landsat9-c2-l1-missing/\" + k.split(\"/\")[-1],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/output/missing_s3.txt\", \"w\") as fp:\n",
    "    for scene in missing_files:\n",
    "        get_dt_str = lambda p: p.split(\"_\")[3]\n",
    "        for asset in missing_files[scene]:\n",
    "            if asset not in excluding:\n",
    "                destination = f\"landsat9-c2-l1/{get_dt_str(scene)}/{scene}/{asset}\"\n",
    "                fp.write(destination)\n",
    "                fp.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108078_20220520_20220520_02_T1/LC09_L1TP_108078_20220520_20220520_02_T1_SAA.TIF' occurred while copying file LC09_L1TP_108078_20220520_20220520_02_T1_SAA.TIF\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108082_20220520_20220520_02_T1/LC09_L1TP_108082_20220520_20220520_02_T1_VZA.TIF' occurred while copying file LC09_L1TP_108082_20220520_20220520_02_T1_VZA.TIF\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108083_20220520_20220520_02_T1/LC09_L1TP_108083_20220520_20220520_02_T1_MTL.txt' occurred while copying file LC09_L1TP_108083_20220520_20220520_02_T1_MTL.txt\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1GT_108057_20220520_20220520_02_T2/LC09_L1GT_108057_20220520_20220520_02_T2_ANG.txt' occurred while copying file LC09_L1GT_108057_20220520_20220520_02_T2_ANG.txt\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108233_20220520_20220520_02_T2/LC09_L1TP_108233_20220520_20220520_02_T2_SZA.TIF' occurred while copying file LC09_L1TP_108233_20220520_20220520_02_T2_SZA.TIF\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108062_20220520_20220520_02_T1/LC09_L1TP_108062_20220520_20220520_02_T1_VAA.TIF' occurred while copying file LC09_L1TP_108062_20220520_20220520_02_T1_VAA.TIF\n",
      "Error [Errno 2] No such file or directory: '../../data/landsat/m2m_download/20220520/LC09_L1TP_108070_20220520_20220520_02_T1/LC09_L1TP_108070_20220520_20220520_02_T1_MTL.xml' occurred while copying file LC09_L1TP_108070_20220520_20220520_02_T1_MTL.xml\n"
     ]
    }
   ],
   "source": [
    "for scene in missing_files:\n",
    "    get_dt_str = lambda p: p.split(\"_\")[3]\n",
    "    for asset in missing_files[scene]:\n",
    "        source = f\"../../data/landsat/m2m_download/{get_dt_str(scene)}/{scene}/{asset}\"\n",
    "        destination = (\n",
    "            f\"../../data/landsat/landsat9-c2-l1/{get_dt_str(scene)}/{scene}/{asset}\"\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "        try:\n",
    "            shutil.copy(source, destination)\n",
    "            # print(f\"File {asset} copied successfully.\")\n",
    "\n",
    "        # For other errors\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e} occurred while copying file {asset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 9439)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_cnt, file_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 9439)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_cnt, file_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/stac/landsat-c2l1/json/20211211/LC09_L1GT_220105_20211211_20220120_02_T2_stac.json'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 11\n"
     ]
    }
   ],
   "source": [
    "export_scenes_list(list(missing_files.keys()), \"batch_ms1\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LC09_L1GT_068110_20220916_20220916_02_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dt_str = lambda p: p.split(\"_\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_pid = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LC09_L1TP_108078_20220520_20220520_02_T1_SAA.TIF'}\n",
      "{'LC09_L1TP_108082_20220520_20220520_02_T1_VZA.TIF'}\n",
      "{'LC09_L1TP_108083_20220520_20220520_02_T1_MTL.txt'}\n",
      "{'LC09_L1GT_108057_20220520_20220520_02_T2_ANG.txt'}\n",
      "{'LC09_L1TP_108233_20220520_20220520_02_T2_SZA.TIF'}\n",
      "{'LC09_L1TP_108062_20220520_20220520_02_T1_VAA.TIF'}\n",
      "{'LC09_L1TP_108070_20220520_20220520_02_T1_MTL.xml'}\n"
     ]
    }
   ],
   "source": [
    "for pid in list(missing_files.keys()):\n",
    "    # pid = \"LC09_L1GT_173020_20220916_20220916_02_T2\"\n",
    "    f_cached = [\n",
    "        f.split(\"/\")[-1]\n",
    "        for f in glob.glob(f\"../../data/landsat/m2m_download/{get_dt_str(pid)}/{pid}/*\")\n",
    "    ]\n",
    "    if set(missing_files[pid]) - set(f_cached):\n",
    "        m_pid.append(pid)\n",
    "        print(set(missing_files[pid]) - set(f_cached))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LC09_L1TP_108078_20220520_20220520_02_T1',\n",
       " 'LC09_L1TP_108082_20220520_20220520_02_T1',\n",
       " 'LC09_L1TP_108083_20220520_20220520_02_T1',\n",
       " 'LC09_L1GT_108057_20220520_20220520_02_T2',\n",
       " 'LC09_L1TP_108233_20220520_20220520_02_T2',\n",
       " 'LC09_L1TP_108062_20220520_20220520_02_T1',\n",
       " 'LC09_L1TP_108070_20220520_20220520_02_T1',\n",
       " 'LC09_L1TP_200044_20221015_20221015_02_T1',\n",
       " 'LC09_L1TP_045016_20221017_20221018_02_T1',\n",
       " 'LC09_L1TP_045014_20221017_20221018_02_T1',\n",
       " 'LC09_L1TP_029047_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029041_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029035_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029044_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029033_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_045007_20221017_20221018_02_T1',\n",
       " 'LC09_L1TP_029046_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029042_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029043_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029036_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_045008_20221017_20221018_02_T2',\n",
       " 'LC09_L1TP_029037_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029031_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029045_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_045015_20221017_20221018_02_T1',\n",
       " 'LC09_L1TP_029032_20221017_20221017_02_T1',\n",
       " 'LC09_L1TP_029034_20221017_20221017_02_T1']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LC09_L1GT_068110_20220916_20220916_02_T2_B4.TIF']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_files[\"LC09_L1GT_068110_20220916_20220916_02_T2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20211211'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestr = \"20220430\"\n",
    "\n",
    "\n",
    "remote_files = [\n",
    "    obj.key.split(\"/\")[-1]\n",
    "    for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/{datestr}\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestr = \"20220430\"\n",
    "\n",
    "\n",
    "remote_files = [\n",
    "    obj.key.split(\"/\")[-1]\n",
    "    for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/{datestr}\")\n",
    "]\n",
    "\n",
    "import glob\n",
    "\n",
    "stac_list = glob.glob(f\"../../data/stac/landsat-c2l1/json/{datestr}/*.json\")\n",
    "\n",
    "\n",
    "def asset_helper(href):\n",
    "    asset = href.split(\"/\")[-1]\n",
    "    if \".\" in asset:\n",
    "        return asset\n",
    "    else:\n",
    "        return asset + \"_stac.json\"\n",
    "\n",
    "\n",
    "for sf in stac_list:\n",
    "    with open(sf, \"r\") as f:\n",
    "        import json\n",
    "\n",
    "        stac_objects = json.load(f)\n",
    "    diff = set(\n",
    "        [asset_helper(obj[\"href\"]) for k, obj in stac_objects[\"assets\"].items()]\n",
    "    ) - set(remote_files)\n",
    "    if diff:\n",
    "        missing_files[stac_objects[\"id\"]] = list(diff)\n",
    "        scene_cnt += 1\n",
    "        file_cnt += len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_stac_from_S3(datestr):\n",
    "    remote_stacs = [\n",
    "        (obj.key, datestr + \"/\" + obj.key.split(\"/\")[-1])\n",
    "        for obj in my_bucket.objects.filter(Prefix=f\"landsat9-c2-l1/{datestr}\")\n",
    "        if obj.key[-9:] == \"stac.json\"\n",
    "    ]\n",
    "    # retrieve stac json from remote S3 bucket if forgot to store a local copy\n",
    "    for obj_key, obj_dest in remote_stacs:\n",
    "        obj_dest = \"../../data/stac/landsat-c2l1/json/\" + obj_dest\n",
    "        if not os.path.exists(obj_dest):\n",
    "            if not os.path.exists(os.path.dirname(obj_dest)):\n",
    "                os.makedirs(os.path.dirname(obj_dest))\n",
    "            my_bucket.download_file(obj_key, obj_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_stacs = [\n",
    "    (obj.key, datestr + \"/\" + obj.key.split(\"/\")[-1])\n",
    "    for obj in my_bucket.objects.filter(Prefix=\"landsat9-c2-l1/20220926\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18379"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remote_stacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_stacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_stac_from_S3(\"20221031\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2021, 10, 31)\n",
    "end_date = date(2022, 11, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "glob(destination + \"/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"../../data/stac/landsat-c2l1/json/\" + datestr\n",
    "destination = \"../../data/stac/landsat-c2l1/json/\" + datestr\n",
    "\n",
    "# code to move the files from sub-folder to main folder.\n",
    "subfolders = os.listdir(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_and_clean_from_subfolder(datestr):\n",
    "    import os\n",
    "    import shutil\n",
    "    from glob import glob\n",
    "\n",
    "    # Define the source and destination path\n",
    "\n",
    "    destination = \"../../data/stac/landsat-c2l1/json/\" + datestr\n",
    "    tmp = \"../../data/temp\"\n",
    "    source_folders = glob(destination + \"/*/\")\n",
    "    # code to move the files from sub-folder to main folder.\n",
    "    for source in source_folders:\n",
    "        files = os.listdir(source)\n",
    "        for file in files:\n",
    "            file_name = os.path.join(source, file)\n",
    "            shutil.move(file_name, tmp)\n",
    "            shutil.rmtree(source)\n",
    "            shutil.move(os.path.join(tmp, file), destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_and_clean_from_subfolder(\"20221031\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_over_daterange(start_date, end_date, move_and_clean_from_subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_over_daterange(start_date, end_date, retrieve_stac_from_S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_files = [\n",
    "    fn.split(\"/\")[-1]\n",
    "    for fn in glob.glob(\"../../data/landsat/m2m_download/20220430/**/*\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17232"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(local_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17215"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remote_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LC09_L1TP_023017_20220430_20220430_02_T2_B4.TIF',\n",
       " 'LC09_L1TP_071014_20220430_20220430_02_T1_B11.TIF',\n",
       " 'LC09_L1TP_128057_20220430_20220430_02_T1_B10.TIF',\n",
       " 'LC09_L1TP_144032_20220430_20220430_02_T1_QA_RADSAT.TIF',\n",
       " 'LC09_L1TP_144032_20220430_20220430_02_T1_SAA.TIF',\n",
       " 'LC09_L1TP_144033_20220430_20220430_02_T1_QA_RADSAT.TIF',\n",
       " 'LC09_L1TP_144033_20220430_20220430_02_T1_SAA.TIF',\n",
       " 'LC09_L1TP_144034_20220430_20220430_02_T1_QA_RADSAT.TIF',\n",
       " 'LC09_L1TP_144034_20220430_20220430_02_T1_SAA.TIF',\n",
       " 'LC09_L1TP_144034_20220430_20220430_02_T1_SZA.TIF',\n",
       " 'LC09_L1TP_160012_20220430_20220430_02_T1_QA_PIXEL.TIF',\n",
       " 'LC09_L1TP_176059_20220430_20220430_02_T1_SZA.TIF',\n",
       " 'LC09_L1TP_176059_20220430_20220430_02_T1_VAA.TIF',\n",
       " 'LC09_L1TP_192010_20220430_20220430_02_T1_SAA.TIF',\n",
       " 'LC09_L1TP_192010_20220430_20220430_02_T1_SZA.TIF',\n",
       " 'LC09_L1TP_192033_20220430_20220430_02_T1_QA_RADSAT.TIF',\n",
       " 'LC09_L1TP_192033_20220430_20220430_02_T1_SAA.TIF'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(local_files) - set(remote_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config = Config(\n",
    "    region_name=\"us-west-1\",\n",
    "    signature_version=\"v4\",\n",
    "    retries={\"max_attempts\": 10, \"mode\": \"standard\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = \"\"\n",
    "SECRET_KEY = \"\"\n",
    "\n",
    "PATH_TO_CSV = \"\"\n",
    "car_dir = Path()\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    "    endpoint_url=ENDPOINT,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(PATH_TO_CSV)\n",
    "\n",
    "\n",
    "def upload_to_aws(local_file, bucket, s3_file):\n",
    "\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print(\"Upload Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(\"Index \", idx)\n",
    "    print(row[\"name\"])\n",
    "    car_target = car_dir / str(row[\"file\"])\n",
    "\n",
    "    if not car_target.exists():\n",
    "        print(row[\"name\"])\n",
    "        print(\"does not exists\")\n",
    "        continue\n",
    "\n",
    "    print(str(car_target), \"<NAME>\", row[\"file\"])\n",
    "    uploaded = upload_to_aws(str(car_target), \"<NAME>\", row[\"file\"])\n",
    "\n",
    "    if not uploaded:\n",
    "        print(row[\"name\"])\n",
    "        print(\"not uploaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
