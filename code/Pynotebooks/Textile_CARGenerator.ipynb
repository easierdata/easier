{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CAR files for each Landsat scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wxzGHl-x0Bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ENV variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = os.getenv('TOKEN')\n",
    "TMPDIR = os.getenv('TMPDIR')\n",
    "DATAROOT = os.getenv('DATAROOT')\n",
    "pow_path = os.getenv('POW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup source and destination directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tar_dir = Path(\"../../data/input/\")\n",
    "source_tars = list(source_tar_dir.glob(\"*.tar\"))\n",
    "extracted_tar_dir = Path(\"../../data/output/\")\n",
    "car_file_dir = Path(\"../../data/car_files/\")\n",
    "pow_path=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract .tar files (Landsat Scenes) to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-Gki9SCm0K16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting TAR file to ../../data/output\n",
      "Extracting TAR file to ../../data/output\n"
     ]
    }
   ],
   "source": [
    "for tar in source_tars:\n",
    "  destination_extracted_tar_file = f\"{extracted_tar_dir}/{tar.stem}\"\n",
    "  print (f\"Extracting TAR file to {extracted_tar_dir}\")\n",
    "  with tarfile.open(str(tar)) as tar:\n",
    "    tar.extractall(path=destination_extracted_tar_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0MnrXHO1dBk"
   },
   "source": [
    "## Generate CARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car_dir.mkdir(parents=True, exist_ok=True) # create car dir automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Tm8pUKGTywWQ"
   },
   "outputs": [],
   "source": [
    "extracted_tars = [x for x in extracted_tar_dir.glob(\"*\") if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E91XahiGyzGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/output/LC09_L2SP_041034_20221005_20221007_02_T1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['name', 'payload_cid', 'piece_size', 'piece_cid', \"file\"])\n",
    "for target in extracted_tars:\n",
    "    print(target)\n",
    "    car_target = Path(f\"{car_file_dir}/{target.stem}.car\")\n",
    "\n",
    "    if car_target.exists():\n",
    "        print(f\"Skipping {car_target.name}\")\n",
    "        continue\n",
    "\n",
    "    # Don't aggregate \n",
    "    # result = subprocess.run([str(pow_path), \"offline\", \"prepare\", \"--json\", str(target), str(car_target)], shell=True, capture_output=True)\n",
    "    \n",
    "    # Aggregate\n",
    "    result = subprocess.run(f\"{str(pow_path)} offline prepare --json --aggregate {str(target)} {str(car_target)} --tmpdir {TMPDIR}\", shell=True, capture_output=True)\n",
    "    #limited tmp folder on GEOG cluster; add tmpdir to redirect tmp files\n",
    "    \n",
    "    try:\n",
    "        result=json.loads(result.stderr.decode('utf-8'))\n",
    "        temp_df = {\"name\": str(car_target.stem), \"payload_cid\": result[\"payload_cid\"], \"piece_size\": result[\"piece_size\"], \"piece_cid\": result[\"piece_cid\"], \"file\": str(car_target.name)}\n",
    "        df = df.append(temp_df, ignore_index=True)\n",
    "        df.to_csv(f\"{str(car_file_dir.parent)}/{str(car_file_dir.stem)}_car_master.csv\") # CHANGE AS REQUIRED\n",
    "        with open(f\"{str(car_file_dir.parent)}/{str(car_file_dir.stem)}_{str(target.stem)}_car_reference.json\",'w',encoding='utf-8') as fw:\n",
    "            json.dump(result,fw,ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"error - {target}  - {e}\")\n",
    "    \n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Textile-CARGenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb06483d433fe4a4167710c74b044303c64c391fff93d157ac52bd32ba531e9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
